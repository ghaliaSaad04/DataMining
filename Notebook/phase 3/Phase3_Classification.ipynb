{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Classification with Decision Trees (Inspired by Lab Guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41d808e",
   "metadata": {},
   "source": [
    "# READ FILE:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf17ec5a",
   "metadata": {},
   "source": [
    "This step initiates the classification and clustering processes by loading a pre-cleaned dataset named \"cleaned_data (1).csv\". This dataset has already undergone essential preprocessing in a prior phase, such as handling missing values, normalizing inputs, and encoding categorical attributes where needed. Using the pd.read_csv() function from pandas, the file is read into a DataFrame (df), setting the stage for further analysis and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_data.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a38eafa",
   "metadata": {},
   "source": [
    "# Feature Selection:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455d94c7",
   "metadata": {},
   "source": [
    "Here, the dataset is split into two parts: features (x) and the target variable (y). The features include all columns except the last one, Accident_Severity, which is the target we want the model to predict. A list of feature names (fn) is extracted from the dataset's columns, and these are used to define the input matrix x. The class labels (accident severity levels) are isolated into the variable y. This separation is essential to train supervised learning models like the Decision Tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn =df.keys().tolist() [:-1]\n",
    "x=df[fn]\n",
    "y=df['Accident_Severity']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ef78f4",
   "metadata": {},
   "source": [
    "# Model Evaluation Function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c2072d",
   "metadata": {},
   "source": [
    "This section defines a reusable function evaluate_model() that encapsulates the full training and evaluation process for a Decision Tree classifier\n",
    " The function accepts training and testing sets, along with a criterion (gini or entropy), then:\n",
    "\n",
    "Instantiates a DecisionTreeClassifier using the specified criterion\n",
    "Trains the model on the training data\n",
    "Predicts labels on the test set\n",
    "Calculates the model's accuracy using accuracy_score()\n",
    "Generates a confusion matrix and visualizes it with ConfusionMatrixDisplay\n",
    "This function returns the trained model and its accuracy score, providing a concise way to evaluate different configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(X_train, X_test, y_train, y_test, criterion):\n",
    "    clf = DecisionTreeClassifier(criterion=criterion, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Criterion: {criterion}, Accuracy: {acc:.4f}\")\n",
    "    ConfusionMatrixDisplay(cm, display_labels=clf.classes_).plot()\n",
    "    plt.title(f\"Confusion Matrix ({criterion})\")\n",
    "    plt.show()\n",
    "    return clf, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226fb0cb",
   "metadata": {},
   "source": [
    "#  Model Evaluation Across Multiple Splits and Criteria:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee51357",
   "metadata": {},
   "source": [
    "This section evaluates the performance of Decision Tree classifiers across different train-test splits and classification criteria. To ensure a robust assessment of model behavior, the dataset is partitioned into three different ratios: 90% training - 10% testing, 80% training - 20% testing, and 70% training - 30% testing. For each partition, two Decision Tree classifiers are built using different splitting criteriaâ€”Gini index and Entropyâ€”to compare their effectiveness under varying amounts of training data.\n",
    "\n",
    "The train_test_split() function is used to create training and testing datasets for each ratio, ensuring that results are consistent by setting random_state=42. A loop iterates over the chosen split ratios and criteria, training the model on the corresponding subset and evaluating it on the test data. The evaluate_model() function encapsulates the training and prediction steps and returns both the trained model and its accuracy.\n",
    "\n",
    "All resultsâ€”including the train-test ratio, criterion used, and resulting accuracyâ€”are stored in a list for comparison. This systematic evaluation allows us to determine how data quantity and splitting strategy influence model performance and whether the Gini or Entropy criterion is more effective for our dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [(0.9, 0.1), (0.8, 0.2), (0.7, 0.3)]\n",
    "results = []\n",
    "for train_size, test_size in splits:\n",
    "    print(f\"\\n--- Train/Test Split: {int(train_size*100)}/{int(test_size*100)} ---\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, train_size=train_size, test_size=test_size, random_state=42)\n",
    "    for criterion in [\"gini\", \"entropy\"]:\n",
    "        clf, acc = evaluate_model(X_train, X_test, y_train, y_test, criterion)\n",
    "        results.append({\"Train Size\": train_size, \"Test Size\": test_size, \"Criterion\": criterion, \"Accuracy\": acc})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14255fcc",
   "metadata": {},
   "source": [
    "# Training the Final Model:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7f6e34",
   "metadata": {},
   "source": [
    "This step involves selecting the best-performing configuration from our earlier evaluation and retraining the Decision Tree classifier on the full training set using those parameters. Based on our previous results, we choose a specific train-test split (`70/30`) and splitting criterion (`entropy`) that yielded the most reliable accuracy and confusion matrix performance.\n",
    "\n",
    "Training the final model on this configuration ensures we capture the most optimal balance between generalization and accuracy. This model will then be used for making predictions on new, unseen data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Train final model (on 70/30 split with 'entropy') for saving/loading\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, train_size=0.7, test_size=0.3, random_state=42)\n",
    "final_model = DecisionTreeClassifier(criterion=\"entropy\", random_state=42)\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cb3b5f",
   "metadata": {},
   "source": [
    "# Saving the Model for New Predictions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adc36d2",
   "metadata": {},
   "source": [
    "To enable reuse of the trained model without needing to retrain it each time, we save it to disk using `joblib`. This is a common best practice in machine learning deployment workflows.\n",
    "\n",
    "Saving the model allows for fast and consistent predictions in production environments or future experiments. It also ensures reproducibility, as the exact trained weights and structure of the model are preserved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "joblib.dump(final_model, \"decision_tree_model.pkl\")\n",
    "\n",
    "# Use the same columns as in training\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "feature_names = X_train.columns  \n",
    "\n",
    "# Create a DataFrame with the same columns\n",
    "new_sample = pd.DataFrame([[5.1, 3.5, 1.4, 0.2] + [0]*10], columns=feature_names)  # Pad the rest if needed\n",
    "loaded_model = joblib.load(\"decision_tree_model.pkl\")\n",
    "prediction = loaded_model.predict(new_sample)\n",
    "print(\"Predicted class for new sample:\", prediction[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f85d2ef",
   "metadata": {},
   "source": [
    "#  Displaying the 70/30 Split Partition:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6509d17c",
   "metadata": {},
   "source": [
    "This step isolates the 70% training / 30% testing configuration from earlier evaluations and displays its a visual representation of the model's performance. The 70/30 split is especially useful for evaluating how well the model generalizes when trained with less data compared to other splits (like 90/10 or 80/20).\n",
    "\n",
    "By focusing on this partition, we can observe whether the model maintains strong predictive power despite having less training data and a larger test set. This is often a good stress test for model robustness.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make sure class names are strings\n",
    "class_names_str = [str(cls) for cls in final_model.classes_]\n",
    "\n",
    "# Plot the tree\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(\n",
    "    final_model,\n",
    "    feature_names=list(x.columns),  # Ensure it's a list of strings\n",
    "    class_names=class_names_str,\n",
    "    filled=True\n",
    ")\n",
    "plt.title(\"Final Decision Tree (Entropy, 70/30)\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50140cb",
   "metadata": {},
   "source": [
    "#  Optional: Visualization by Split Size and Criterion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b1c708",
   "metadata": {},
   "source": [
    "To better understand how the model's behavior changes with different train-test splits and criteria, we visualize key metrics. These visualizations make it easier to detect patterns and trade-offsâ€”for example, whether a larger training set consistently improves accuracy or whether one criterion outperforms another in terms of class balance.\n",
    "\n",
    "Optional visualizations help communicate results more clearly, and support better decision-making regarding model deployment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Try different test sizes and both criteria\n",
    "split_sizes = [0.3, 0.2, 0.1]\n",
    "criteria = ['gini', 'entropy']\n",
    "\n",
    "for split in split_sizes:\n",
    "    for criterion in criteria:\n",
    "        print(f\"\\nðŸ”¹ Criterion: {criterion.upper()}, Split: {int((1-split)*100)}/{int(split*100)}\")\n",
    "\n",
    "        # Split the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            x, y, test_size=split, random_state=42\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        model = DecisionTreeClassifier(criterion=criterion, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy: {acc:.2f}\")\n",
    "\n",
    "        # Plot the tree\n",
    "        plt.figure(figsize=(13, 2))\n",
    "        plot_tree(\n",
    "            model,\n",
    "            feature_names=x.columns.astype(str),\n",
    "            class_names=[str(cls) for cls in model.classes_],\n",
    "            filled=True\n",
    "        )\n",
    "        plt.title(f\"Decision Tree ({criterion.capitalize()}) â€” Split {int((1-split)*100)}/{int(split*100)}\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96abeab3",
   "metadata": {},
   "source": [
    " # Final Justification and Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843afcc4",
   "metadata": {},
   "source": [
    "After evaluating the Decision Tree classifier using both the Gini index and Entropy across three different train-test splits (90/10, 80/20, 70/30), we observe the following patterns:\n",
    "\n",
    "- **Accuracy Stability:** Both criteria performed similarly across splits, with minor differences. This indicates that the model is not overly sensitive to the choice of criterion on this dataset.\n",
    "- **Train-Test Tradeoff:** As expected, models trained on larger training sets (e.g., 90%) tended to perform slightly better due to more information being available during training. However, the difference was not dramatic, suggesting the dataset is large and diverse enough to allow flexible partitioning.\n",
    "- **Confusion Matrices:** These visualizations helped identify where the model struggled (e.g., if certain classes were consistently misclassified). If significant misclassification was seen in a particular class, it might be worth exploring further class-specific metrics or balancing the dataset.\n",
    "\n",
    "Based on overall performance, a **train-test split of 80/20 with the Gini index** appears to offer a good balance of performance and generalization. However, both criteria are viable could further improve performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
