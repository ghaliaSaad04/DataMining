{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 3: Classification with Decision Trees (Inspired by Lab Guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41d808e",
   "metadata": {},
   "source": [
    "# READ FILE:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf17ec5a",
   "metadata": {},
   "source": [
    "This step initiates the classification and clustring processes by loading a pre-cleaned dataset named \"cleaned_data (1).csv\". This dataset has already undergone essential preprocessing in a prior phase, such as handling missing values, normalizing inputs, and encoding categorical attributes where needed. Using the pd.read_csv() function from pandas, the file is read into a DataFrame (df), setting the stage for further analysis and model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned_data.csv')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a38eafa",
   "metadata": {},
   "source": [
    "# Feature Selection:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455d94c7",
   "metadata": {},
   "source": [
    "Here, the dataset is split into two parts: features (x) and the target variable (y). The features include all columns except the last one, Accident_Severity, which is the target we want the model to predict. A list of feature names (fn) is extracted from the dataset's columns, and these are used to define the input matrix x. The class labels (accident severity levels) are isolated into the variable y. This separation is essential to train supervised learning models like the Decision Tree classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn =df.keys().tolist() [:-1]\n",
    "x=df[fn]\n",
    "y=df['Accident_Severity']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ef78f4",
   "metadata": {},
   "source": [
    "# Model Evaluation Function:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c2072d",
   "metadata": {},
   "source": [
    "This section defines a reusable function evaluate_model() that encapsulates the full training and evaluation process for a Decision Tree classifier\n",
    " The function accepts training and testing sets, along with a criterion (gini or entropy), then:\n",
    "\n",
    "Instantiates a DecisionTreeClassifier using the specified criterion\n",
    "Trains the model on the training data\n",
    "Predicts labels on the test set\n",
    "Calculates the model's accuracy using accuracy_score()\n",
    "Generates a confusion matrix and visualizes it with ConfusionMatrixDisplay\n",
    "This function returns the trained model and its accuracy score, providing a concise way to evaluate different configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_model(X_train, X_test, y_train, y_test, criterion):\n",
    "    clf = DecisionTreeClassifier(criterion=criterion, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f\"Criterion: {criterion}, Accuracy: {acc:.4f}\")\n",
    "    ConfusionMatrixDisplay(cm, display_labels=clf.classes_).plot()\n",
    "    plt.title(f\"Confusion Matrix ({criterion})\")\n",
    "    plt.show()\n",
    "    return clf, acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226fb0cb",
   "metadata": {},
   "source": [
    "#  Model Evaluation Across Multiple Splits and Criteria:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aee51357",
   "metadata": {},
   "source": [
    "This section evaluates the performance of Decision Tree classifiers across different train-test splits and classification criteria. To ensure a robust assessment of model behavior, the dataset is partitioned into three different ratios: 90% training - 10% testing, 80% training - 20% testing, and 70% training - 30% testing. For each partition, two Decision Tree classifiers are built using different splitting criteriaâ€”Gini index and Entropyâ€”to compare their effectiveness under varying amounts of training data.\n",
    "\n",
    "The train_test_split() function is used to create training and testing datasets for each ratio, ensuring that results are consistent by setting random_state=42. A loop iterates over the chosen split ratios and criteria, training the model on the corresponding subset and evaluating it on the test data. The evaluate_model() function encapsulates the training and prediction steps and returns both the trained model and its accuracy.\n",
    "\n",
    "All resultsâ€”including the train-test ratio, criterion used, and resulting accuracyâ€”are stored in a list for comparison. This systematic evaluation allows us to determine how data quantity and splitting strategy influence model performance and whether the Gini or Entropy criterion is more effective for our dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = [(0.9, 0.1), (0.8, 0.2), (0.7, 0.3)]\n",
    "results = []\n",
    "for train_size, test_size in splits:\n",
    "    print(f\"\\n--- Train/Test Split: {int(train_size*100)}/{int(test_size*100)} ---\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(x, y, train_size=train_size, test_size=test_size, random_state=42)\n",
    "    for criterion in [\"gini\", \"entropy\"]:\n",
    "        clf, acc = evaluate_model(X_train, X_test, y_train, y_test, criterion)\n",
    "        results.append({\"Train Size\": train_size, \"Test Size\": test_size, \"Criterion\": criterion, \"Accuracy\": acc})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "print(\"\\nSummary of Results:\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Train final model (on 70/30 split with 'entropy') for saving/loading\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, train_size=0.7, test_size=0.3, random_state=42)\n",
    "final_model = DecisionTreeClassifier(criterion=\"entropy\", random_state=42)\n",
    "final_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "joblib.dump(final_model, \"decision_tree_model.pkl\")\n",
    "\n",
    "# Use the same columns as in training\n",
    "import pandas as pd\n",
    "\n",
    "# You need the original feature column names from training\n",
    "# Assuming you saved them like this:\n",
    "feature_names = X_train.columns  # Save these when training\n",
    "\n",
    "# Create a DataFrame with the same columns\n",
    "new_sample = pd.DataFrame([[5.1, 3.5, 1.4, 0.2] + [0]*10], columns=feature_names)  # Pad the rest if needed\n",
    "loaded_model = joblib.load(\"decision_tree_model.pkl\")\n",
    "prediction = loaded_model.predict(new_sample)\n",
    "print(\"Predicted class for new sample:\", prediction[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Make sure class names are strings\n",
    "class_names_str = [str(cls) for cls in final_model.classes_]\n",
    "\n",
    "# Plot the tree\n",
    "plt.figure(figsize=(12, 8))\n",
    "plot_tree(\n",
    "    final_model,\n",
    "    feature_names=list(x.columns),  # Ensure it's a list of strings\n",
    "    class_names=class_names_str,\n",
    "    filled=True\n",
    ")\n",
    "plt.title(\"Final Decision Tree (Entropy, 70/30)\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Try different test sizes and both criteria\n",
    "split_sizes = [0.3, 0.2, 0.1]\n",
    "criteria = ['gini', 'entropy']\n",
    "\n",
    "for split in split_sizes:\n",
    "    for criterion in criteria:\n",
    "        print(f\"\\nðŸ”¹ Criterion: {criterion.upper()}, Split: {int((1-split)*100)}/{int(split*100)}\")\n",
    "\n",
    "        # Split the data\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            x, y, test_size=split, random_state=42\n",
    "        )\n",
    "\n",
    "        # Train the model\n",
    "        model = DecisionTreeClassifier(criterion=criterion, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluate\n",
    "        y_pred = model.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Accuracy: {acc:.2f}\")\n",
    "\n",
    "        # Plot the tree\n",
    "        plt.figure(figsize=(13, 2))\n",
    "        plot_tree(\n",
    "            model,\n",
    "            feature_names=x.columns.astype(str),\n",
    "            class_names=[str(cls) for cls in model.classes_],\n",
    "            filled=True\n",
    "        )\n",
    "        plt.title(f\"Decision Tree ({criterion.capitalize()}) â€” Split {int((1-split)*100)}/{int(split*100)}\")\n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
